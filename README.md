# Deep Research Agent

> Browser-powered deep research agent for AI coding assistants. No API keys required for basic tools â€” optional LLM backend enables fully autonomous research.

An [MCP](https://modelcontextprotocol.io/) server that gives any AI assistant the ability to search the web, read pages, take screenshots, and interact with sites â€” all through a real browser. Uses Bing for search and Playwright for browser automation, so there are **zero API keys** to configure for the core tools.

Optionally, configure an LLM backend (GitHub Copilot SDK or any OpenAI-compatible API) to unlock the **`deep_research` tool** â€” a fully autonomous research pipeline that decomposes topics, searches, extracts content, cross-references findings, fills gaps, and produces structured reports with citations, all without host LLM involvement.

## Features

- ğŸ” **Browser-based web search** â€” Bing via Playwright (stealth user-agent), no API keys needed
- ğŸ“„ **Full page content extraction** â€” JavaScript-rendered sites converted to clean Markdown via Readability + Turndown
- ğŸ“¸ **Screenshots** â€” capture full or viewport screenshots for visual analysis
- ğŸ–±ï¸ **Interactive navigation** â€” click elements, fill forms, follow links
- ğŸ”Œ **Replaceable search backend** â€” swap Bing for any search API by implementing the `SearchEngine` interface
- ğŸ¤– **Works with any MCP-compatible AI assistant** â€” Copilot CLI, Claude Code, Codex, VS Code, and more
- ğŸ“ **Structured logging** â€” all operations logged to stderr with timestamps, durations, and error context
- ğŸ§© **Research workflow prompt** â€” built-in `deep-research` prompt guides the host LLM through a complete multi-step research workflow
- ğŸ§  **Autonomous deep research** â€” optional `deep_research` tool with built-in LLM runs the full research pipeline internally (decompose â†’ search â†’ extract â†’ cross-reference â†’ fill gaps â†’ synthesize report)
- ğŸ”— **Pluggable LLM backend** â€” GitHub Copilot SDK (uses your Copilot subscription) or any OpenAI-compatible API (OpenAI, GitHub Models, Azure, Anthropic, etc.)

## Design

### How It Works

This project is an **MCP server** â€” it exposes browser-based research tools that a host AI assistant (Copilot CLI, Claude Code, Codex) orchestrates. The host LLM decides what to search, which pages to visit, and how to synthesize findings.

When an **LLM backend is configured** (`LLM_PROVIDER` env var), the server also exposes the `deep_research` tool, which uses the internal LLM to autonomously execute the full research workflow without host LLM involvement.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Host LLM (Copilot CLI / Claude Code / Codex)              â”‚
â”‚  - Calls individual tools (web_search, visit_page, etc.)   â”‚
â”‚  - OR calls deep_research for fully autonomous research    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ MCP Protocol (stdio)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deep Research Agent (this server)                          â”‚
â”‚                                                            â”‚
â”‚  Tools Layer          Services Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ web_search   â”‚â”€â”€â”€â–¶â”‚ SearchService                    â”‚  â”‚
â”‚  â”‚ visit_page   â”‚    â”‚  â””â”€ BingSearchEngine (default)   â”‚  â”‚
â”‚  â”‚ screenshot   â”‚â”€â”€â”€â–¶â”‚  â””â”€ DuckDuckGoEngine (alt)       â”‚  â”‚
â”‚  â”‚ click_elementâ”‚    â”‚  â””â”€ YourCustomEngine (plug in)   â”‚  â”‚
â”‚  â”‚ get_links    â”‚â”€â”€â”€â–¶â”‚ BrowserService (Playwright)      â”‚  â”‚
â”‚  â”‚ list_pages   â”‚    â”‚  â””â”€ Stealth user-agent           â”‚  â”‚
â”‚  â”‚ close_page   â”‚    â”‚  â””â”€ Page lifecycle management    â”‚  â”‚
â”‚  â”‚              â”‚    â”‚ ContentExtractor                  â”‚  â”‚
â”‚  â”‚ deep_researchâ”‚    â”‚  â””â”€ Readability + Turndown        â”‚  â”‚
â”‚  â”‚  (optional)  â”‚â”€â”€â”€â–¶â”‚  â””â”€ JSDOM (quiet virtual console) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ LLMService (optional)             â”‚  â”‚
â”‚                      â”‚  â””â”€ CopilotLLMProvider            â”‚  â”‚
â”‚  Prompts Layer       â”‚  â””â”€ DirectAPILLMProvider          â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚deep-research â”‚    Logger (stderr, structured JSON)      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chromium (headless, auto-installed by Playwright)          â”‚
â”‚  â””â”€ Bing search, page rendering, screenshots               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Design Decisions

| Decision | Rationale |
|----------|-----------|
| **MCP server, not standalone agent** | Universal compatibility â€” works with any MCP host (Copilot, Claude Code, Codex). The host LLM does the reasoning for basic tools. |
| **Optional embedded LLM** | When `LLM_PROVIDER` is set, the `deep_research` tool uses an internal LLM to run autonomously. When unset, the server behaves exactly as before â€” no breaking changes. |
| **Pluggable LLM backend** | The `LLMProvider` interface lets you swap between Copilot SDK, OpenAI, Azure, Anthropic, or any OpenAI-compatible API. |
| **Bing as default search engine** | DuckDuckGo serves CAPTCHAs to headless browsers. Google blocks by IP. Bing works reliably with a stealth user-agent. |
| **Stealth user-agent** | Search engines detect `HeadlessChrome`. We set `Chrome/131.0.0.0` + realistic viewport/locale to avoid bot detection. |
| **Replaceable search backend** | The `SearchEngine` interface lets you swap Bing for any API (Tavily, Brave, Exa) with a single class change. |
| **No LLM API dependency** | The host provides the LLM for basic tools. Zero API keys, zero cost, works offline (except for web access). The autonomous `deep_research` tool optionally requires an LLM backend. |
| **Readability + Turndown** | Mozilla Readability strips boilerplate, Turndown converts to Markdown â€” clean content for LLM consumption. |
| **Structured logging to stderr** | Stdout is reserved for MCP protocol. All logs go to stderr with `[timestamp] [LEVEL] [component] message {metadata}`. |

## Quick Install

### GitHub Copilot CLI

Add to your project's `.github/copilot-mcp.json` (or user-level MCP config):

```json
{
  "mcpServers": {
    "deep-research": {
      "command": "npx",
      "args": ["-y", "deep-research-agent"]
    }
  }
}
```

### Claude Code

```bash
claude mcp add deep-research -- npx -y deep-research-agent
```

### VS Code (Copilot Chat)

Add to your VS Code `settings.json`:

```json
{
  "mcp": {
    "servers": {
      "deep-research": {
        "command": "npx",
        "args": ["-y", "deep-research-agent"]
      }
    }
  }
}
```

### OpenAI Codex / Other MCP Hosts

Use the generic MCP server configuration:

```json
{
  "mcpServers": {
    "deep-research": {
      "command": "npx",
      "args": ["-y", "deep-research-agent"]
    }
  }
}
```

### Environment Variables

#### Core

| Variable | Default | Description |
|----------|---------|-------------|
| `LOG_LEVEL` | `info` | Logging verbosity: `debug`, `info`, `warn`, `error` |

#### LLM Backend (optional â€” enables `deep_research` tool)

| Variable | Values | Default | Description |
|----------|--------|---------|-------------|
| `LLM_PROVIDER` | `copilot`, `openai` | _(none â€” tool not registered)_ | Selects the LLM backend. When unset, `deep_research` is not available. |
| `LLM_MODEL` | Model name | `gpt-4o` | Model to use for LLM completions |
| `GITHUB_TOKEN` | GitHub PAT | _(none)_ | Required for `copilot` backend (also checks `GH_TOKEN`, `COPILOT_GITHUB_TOKEN`) |
| `LLM_API_KEY` | API key | _(none)_ | Required for `openai` backend |
| `LLM_BASE_URL` | URL | `https://api.openai.com/v1` | API base URL for `openai` backend |
| `LLM_MAX_TOKENS` | Number | `4096` | Max tokens for `openai` backend |

**Example â€” Copilot SDK backend (uses your GitHub Copilot subscription):**

```json
{
  "mcpServers": {
    "deep-research": {
      "command": "npx",
      "args": ["-y", "deep-research-agent"],
      "env": {
        "LLM_PROVIDER": "copilot"
      }
    }
  }
}
```

**Example â€” GitHub Models backend:**

```json
{
  "mcpServers": {
    "deep-research": {
      "command": "npx",
      "args": ["-y", "deep-research-agent"],
      "env": {
        "LLM_PROVIDER": "openai",
        "LLM_API_KEY": "<your-github-token>",
        "LLM_BASE_URL": "https://models.github.ai/inference",
        "LLM_MODEL": "openai/gpt-4.1"
      }
    }
  }
}
```

## Available Tools

### `web_search`

Search the web using Bing. Returns titles, URLs, and snippets.

| Parameter      | Type   | Required | Default | Description              |
| -------------- | ------ | -------- | ------- | ------------------------ |
| `query`        | string | yes      | â€”       | Search query             |
| `num_results`  | number | no       | 10      | Number of results to return |

### `visit_page`

Visit a URL and extract the page content as Markdown. Renders JavaScript before extraction.

| Parameter        | Type    | Required | Default | Description                  |
| ---------------- | ------- | -------- | ------- | ---------------------------- |
| `url`            | string  | yes      | â€”       | URL to visit                 |
| `extract_links`  | boolean | no       | false   | Also return an array of links |

### `take_screenshot`

Capture a screenshot of a page as a base64-encoded PNG.

| Parameter    | Type    | Required | Default | Description                    |
| ------------ | ------- | -------- | ------- | ------------------------------ |
| `url`        | string  | yes      | â€”       | URL to screenshot              |
| `full_page`  | boolean | no       | false   | Capture the full scrollable page |

### `click_element`

Click an element on an already-open page using a CSS selector.

| Parameter   | Type   | Required | Description                    |
| ----------- | ------ | -------- | ------------------------------ |
| `page_id`   | string | yes      | ID of an open page             |
| `selector`  | string | yes      | CSS selector of the element    |

### `get_page_links`

Extract all links from an open page.

| Parameter | Type   | Required | Description        |
| --------- | ------ | -------- | ------------------ |
| `page_id` | string | yes      | ID of an open page |

### `list_open_pages`

List all currently open browser pages. Takes no parameters.

### `close_page`

Close a browser page.

| Parameter | Type   | Required | Description          |
| --------- | ------ | -------- | -------------------- |
| `page_id` | string | yes      | ID of the page to close |

### `deep_research`

_(Only available when `LLM_PROVIDER` is configured)_

Perform fully autonomous deep research on a topic. The server internally runs a 7-step pipeline using its built-in LLM â€” no host LLM reasoning required.

| Parameter | Type   | Required | Default    | Description                                                  |
| --------- | ------ | -------- | ---------- | ------------------------------------------------------------ |
| `topic`   | string | yes      | â€”          | The research topic or question                               |
| `depth`   | string | no       | `standard` | Research depth: `quick`, `standard`, or `deep`               |

**What it does internally:**

| Step | Action | Depth: quick | standard | deep |
|------|--------|:---:|:---:|:---:|
| 1. Decompose | Break topic into sub-questions | 3 | 5 | 8 |
| 2. Search | Generate queries and search | per sub-question | per sub-question | per sub-question |
| 3. Extract | Visit top pages, extract facts via LLM | 5 pages | 10 pages | 20 pages |
| 4. Cross-reference | Identify consensus, conflicts, gaps | âœ“ | âœ“ | âœ“ |
| 5. Fill gaps | Additional search rounds for gaps | 1 round | 2 rounds | 3 rounds |
| 6-7. Synthesize | Produce structured report with citations | âœ“ | âœ“ | âœ“ |

Safety limits: max 20K chars per page extraction, visited URL deduplication, JSON parse fallbacks.

## Available Prompts

### `deep-research`

A guided research workflow template that instructs the assistant to perform iterative, multi-source research with built-in citation tracking and verification.

| Parameter | Type   | Required | Default    | Description                                                  |
| --------- | ------ | -------- | ---------- | ------------------------------------------------------------ |
| `topic`   | string | yes      | â€”          | The research topic or question                               |
| `depth`   | string | no       | `standard` | Research depth: `quick` (3 sub-questions), `standard` (5), or `deep` (7) |

The prompt guides the assistant through a structured workflow:

1. **Decompose** the topic into sub-questions
2. **Search** for each sub-question
3. **Extract** content from the most relevant results
4. **Cross-reference** findings across sources
5. **Fill gaps** with follow-up searches
6. **Synthesize** findings into a coherent answer
7. **Report** with inline citations and a source list

## Project Structure

```
src/
â”œâ”€â”€ index.ts                        # Entry point â€” stdio transport, lifecycle management
â”œâ”€â”€ server.ts                       # MCP server wiring â€” creates services, registers tools/prompts
â”œâ”€â”€ logger.ts                       # Structured logger (stderr, level-based, JSON metadata)
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ web-search.ts               # web_search tool
â”‚   â”œâ”€â”€ visit-page.ts               # visit_page tool
â”‚   â”œâ”€â”€ take-screenshot.ts          # take_screenshot tool
â”‚   â”œâ”€â”€ page-actions.ts             # click_element, get_page_links, list_open_pages, close_page
â”‚   â””â”€â”€ deep-research.ts            # deep_research tool (autonomous 7-step pipeline)
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ research-workflow.ts        # deep-research prompt (7-step guided workflow for host LLM)
â””â”€â”€ services/
    â”œâ”€â”€ browser.ts                  # Playwright browser lifecycle + stealth settings
    â”œâ”€â”€ search-engine.ts            # SearchEngine interface + SearchService wrapper
    â”œâ”€â”€ content-extractor.ts        # HTML â†’ Markdown (Readability + Turndown + quiet JSDOM)
    â”œâ”€â”€ llm-provider.ts             # LLMProvider interface + LLMService wrapper
    â”œâ”€â”€ search-backends/
    â”‚   â”œâ”€â”€ bing.ts                 # Default â€” Bing search with URL redirect decoding
    â”‚   â””â”€â”€ duckduckgo.ts           # Alternative â€” DuckDuckGo (may CAPTCHA in some environments)
    â””â”€â”€ llm-backends/
        â”œâ”€â”€ direct-api.ts           # OpenAI-compatible REST API backend
        â””â”€â”€ copilot.ts              # GitHub Copilot SDK backend
```

## Custom Search Backend

The search backend is replaceable. Implement the `SearchEngine` interface to use any search API:

```typescript
import { SearchEngine, SearchResult } from './services/search-engine.js';

class MyCustomSearch implements SearchEngine {
  name = 'my-search';

  async search(query: string, numResults?: number): Promise<SearchResult[]> {
    // Call your preferred search API (Tavily, Brave, Exa, etc.)
    const response = await fetch(`https://api.example.com/search?q=${query}`);
    const data = await response.json();

    return data.results.map((r: any) => ({
      title: r.title,
      url: r.url,
      snippet: r.description,
    }));
  }
}
```

Then update `src/server.ts` to use your backend:

```typescript
const searchEngine = new MyCustomSearch();  // instead of BingSearchEngine
```

## Custom LLM Backend

The LLM backend is also replaceable. Implement the `LLMProvider` interface:

```typescript
import { LLMProvider, LLMCompletionResult } from './services/llm-provider.js';

class MyLLMProvider implements LLMProvider {
  name = 'my-llm';

  async initialize(): Promise<void> {
    // Set up connections, load models, etc.
  }

  async dispose(): Promise<void> {
    // Clean up resources
  }

  async complete(systemPrompt: string, userPrompt: string): Promise<LLMCompletionResult> {
    // Call your LLM API
    return {
      content: 'response text',
      model: 'my-model',
      usage: { promptTokens: 100, completionTokens: 50 },
    };
  }
}
```

Then add it as a case in `createLLMProvider()` in `src/server.ts`.

## Known Issues & Remaining Work

### Search Engine Reliability

| Engine | Status | Notes |
|--------|--------|-------|
| **Bing** (default) | âœ… Works | Reliable with stealth user-agent. URLs decoded from Bing redirects. |
| **DuckDuckGo** | âš ï¸ CAPTCHAs | Serves "select all ducks" CAPTCHA to headless browsers. Kept as alternative. |
| **Google** | âŒ Blocked | Blocks headless Chrome by IP (`/sorry/` redirect). Not implemented. |

Bing may eventually start blocking headless browsers too. The replaceable backend architecture makes it easy to switch to a paid search API when needed.

### Not Yet Implemented

- **npm publish** â€” The package is not yet published to npm. Currently install from source. Run `npm publish` to make `npx -y deep-research-agent` work globally.
- **Parallel sub-question execution** â€” The `deep_research` tool processes sub-questions sequentially. Parallel execution could speed up research.
- **Session persistence** â€” Browser pages are lost when the server restarts. No cross-session memory.
- **Token/cost budgeting** â€” No mechanism to limit how many LLM calls or pages the `deep_research` tool uses.
- **Rate limiting** â€” No throttling between rapid Bing searches. Heavy use may trigger Bing bot detection.
- **Authentication support** â€” Cannot log into sites that require authentication.
- **PDF/document extraction** â€” Only HTML pages are supported. PDFs, Word docs, etc. are not extracted.
- **Vector store / long-term memory** â€” No semantic storage of past research findings.
- **Streaming LLM output** â€” The `deep_research` tool waits for complete LLM responses; no streaming progress updates to the client.

### Operational Notes

- **First tool call is slow (~3-8s)** â€” Chromium browser launch happens lazily on first use. Subsequent calls reuse the browser instance.
- **`networkidle` wait strategy** â€” `visit_page` and `take_screenshot` wait for network idle, which can be slow on heavy sites. Consider adding a timeout parameter.
- **Stderr logging** â€” All logs go to stderr (stdout is MCP protocol). Set `LOG_LEVEL=debug` for full detail, `LOG_LEVEL=error` for quiet operation.
- **JSDOM CSS warnings suppressed** â€” Modern CSS (`:has()`, nesting) triggers harmless `Could not parse CSS stylesheet` errors in JSDOM. These are silenced via `VirtualConsole`.

## Development

```bash
git clone <repo-url>
cd agent_mobile
npm install
npm run build
npm start
```

| Script          | Description                              |
| --------------- | ---------------------------------------- |
| `npm run build` | Compile TypeScript to `dist/`            |
| `npm start`     | Start the MCP server (stdio transport)   |
| `npm run dev`   | Build in watch mode for development      |

## Requirements

- **Node.js** â‰¥ 18
- **Chromium** â€” auto-installed by Playwright during `npm install`
- **For `deep_research` tool** â€” one of:
  - GitHub Copilot subscription + `@github/copilot-sdk` (installed automatically as optional dependency)
  - Any OpenAI-compatible API key

## License

MIT
